{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximação da quantidade de linhas esperadas no arquivo final \n",
    "TOTAL_ROW_COUNT = None\n",
    "# Randomizar amostras coletadas de cada arquivo\n",
    "DO_RANDOMIZE_SAMPLE_ROWS = True\n",
    "# Tipo de arquivo a ser gerado\n",
    "OUTPUT_FILE_TYPE = 'parquet' # 'csv' ou 'parquet'\n",
    "# Rodar ou não a visualização dos recursos (Demora muito mais tempo)\n",
    "RUN_RESOURCE_VISUALIZATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install requests pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, requests, os, random\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.functions import regexp_replace, to_date, col, trim, substring, when\n",
    "\n",
    "conf = SparkConf().set(\"spark.driver.memory\", \"12g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_file(df: DataFrame, path: str):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)\n",
    "\tif OUTPUT_FILE_TYPE == 'csv':\n",
    "\t\tdf.write.csv(f'{path}/df.csv', header=True, mode='overwrite')\n",
    "\telse:\n",
    "\t\tdf.write.parquet(f'{path}/df.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração Manual e manutenção da integridade da zona Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "planilhas = [\n",
    "\t'planilha_2012',\n",
    "\t'planilha_2013',\n",
    "\t'planilha_2014',\n",
    "\t'planilha_2015',\n",
    "\t'planilha_2016',\n",
    "\t'planilha_2017',\n",
    "\t'planilha_2018',\n",
    "\t'planilha_2019',\n",
    "\t'planilha_2020',\n",
    "\t'planilha_2021',\n",
    "\t'planilha_2022',\n",
    "\t'planilha_2023',\n",
    "\t'planilha_2024',\n",
    "]\n",
    "\n",
    "for planilha in planilhas:\n",
    "\tif not os.path.exists(f'data/staging/{planilha}.zip'):\n",
    "\t\turl = f'https://www.bcb.gov.br/pda/desig/{planilha}.zip'\n",
    "\n",
    "\t\tprint(f'Baixando arquivo \"{planilha}.zip\"...')\n",
    "\t\tresponse = requests.get(url)\n",
    "\n",
    "\t\twith open(f'data/staging/{planilha}.zip', 'wb') as f:\n",
    "\t\t\tf.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando para zona Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/raw'):\n",
    "\tos.makedirs('data/raw')\n",
    "\n",
    "for planilha in planilhas:\n",
    "    zip_obj = zipfile.ZipFile(f'data/staging/{planilha}.zip', 'r')\n",
    "    extracted_files = zip_obj.namelist()\n",
    "\n",
    "    for file in extracted_files:\n",
    "        extracted_path = os.path.join(f'data/raw', file)\n",
    "        \n",
    "        if not os.path.exists(extracted_path):\n",
    "            print(f'Extraindo {file}...')\n",
    "            try:\n",
    "                zip_obj.extract(file, 'data/raw')\n",
    "            except zipfile.BadZipFile:\n",
    "                print(f\"Erro: O arquivo {planilha}.zip está corrompido.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao extrair {file}: {e}\")\n",
    "\n",
    "    zip_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/03 20:00:56 WARN Utils: Your hostname, administrador-Inspiron-3501 resolves to a loopback address: 127.0.1.1; using 10.18.6.197 instead (on interface wlp0s20f3)\n",
      "24/10/03 20:00:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/03 20:00:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"Operacoes Creditarias\" em PySpark 3.5.3\n",
      "Processando o arquivo planilha_201206.csv\n",
      "Processando o arquivo planilha_201207.csv\n",
      "Processando o arquivo planilha_201208.csv\n",
      "Processando o arquivo planilha_201209.csv\n",
      "Processando o arquivo planilha_201210.csv\n",
      "Processando o arquivo planilha_201211.csv\n",
      "Processando o arquivo planilha_201212.csv\n",
      "Processando o arquivo planilha_201301.csv\n",
      "Processando o arquivo planilha_201302.csv\n",
      "Processando o arquivo planilha_201303.csv\n",
      "Processando o arquivo planilha_201304.csv\n",
      "Processando o arquivo planilha_201305.csv\n",
      "Processando o arquivo planilha_201306.csv\n",
      "Processando o arquivo planilha_201307.csv\n",
      "Processando o arquivo planilha_201308.csv\n",
      "Processando o arquivo planilha_201309.csv\n",
      "Processando o arquivo planilha_201310.csv\n",
      "Processando o arquivo planilha_201311.csv\n",
      "Processando o arquivo planilha_201312.csv\n",
      "Processando o arquivo planilha_201401.csv\n",
      "Processando o arquivo planilha_201402.csv\n",
      "Processando o arquivo planilha_201403.csv\n",
      "Processando o arquivo planilha_201404.csv\n",
      "Processando o arquivo planilha_201405.csv\n",
      "Processando o arquivo planilha_201406.csv\n",
      "Processando o arquivo planilha_201407.csv\n",
      "Processando o arquivo planilha_201408.csv\n",
      "Processando o arquivo planilha_201409.csv\n",
      "Processando o arquivo planilha_201410.csv\n",
      "Processando o arquivo planilha_201411.csv\n",
      "Processando o arquivo planilha_201412.csv\n",
      "Processando o arquivo planilha_201501.csv\n",
      "Processando o arquivo planilha_201502.csv\n",
      "Processando o arquivo planilha_201503.csv\n",
      "Processando o arquivo planilha_201504.csv\n",
      "Processando o arquivo planilha_201505.csv\n",
      "Processando o arquivo planilha_201506.csv\n",
      "Processando o arquivo planilha_201507.csv\n",
      "Processando o arquivo planilha_201508.csv\n",
      "Processando o arquivo planilha_201509.csv\n",
      "Processando o arquivo planilha_201510.csv\n",
      "Processando o arquivo planilha_201511.csv\n",
      "Processando o arquivo planilha_201512.csv\n",
      "Processando o arquivo planilha_201601.csv\n",
      "Processando o arquivo planilha_201602.csv\n",
      "Processando o arquivo planilha_201603.csv\n",
      "Processando o arquivo planilha_201604.csv\n",
      "Processando o arquivo planilha_201605.csv\n",
      "Processando o arquivo planilha_201606.csv\n",
      "Processando o arquivo planilha_201607.csv\n",
      "Processando o arquivo planilha_201608.csv\n",
      "Processando o arquivo planilha_201609.csv\n",
      "Processando o arquivo planilha_201610.csv\n",
      "Processando o arquivo planilha_201611.csv\n",
      "Processando o arquivo planilha_201612.csv\n",
      "Processando o arquivo planilha_201701.csv\n",
      "Processando o arquivo planilha_201702.csv\n",
      "Processando o arquivo planilha_201703.csv\n",
      "Processando o arquivo planilha_201704.csv\n",
      "Processando o arquivo planilha_201705.csv\n",
      "Processando o arquivo planilha_201706.csv\n",
      "Processando o arquivo planilha_201707.csv\n",
      "Processando o arquivo planilha_201708.csv\n",
      "Processando o arquivo planilha_201709.csv\n",
      "Processando o arquivo planilha_201710.csv\n",
      "Processando o arquivo planilha_201711.csv\n",
      "Processando o arquivo planilha_201712.csv\n",
      "Processando o arquivo planilha_201801.csv\n",
      "Processando o arquivo planilha_201802.csv\n",
      "Processando o arquivo planilha_201803.csv\n",
      "Processando o arquivo planilha_201804.csv\n",
      "Processando o arquivo planilha_201805.csv\n",
      "Processando o arquivo planilha_201806.csv\n",
      "Processando o arquivo planilha_201807.csv\n",
      "Processando o arquivo planilha_201808.csv\n",
      "Processando o arquivo planilha_201809.csv\n",
      "Processando o arquivo planilha_201810.csv\n",
      "Processando o arquivo planilha_201811.csv\n",
      "Processando o arquivo planilha_201812.csv\n",
      "Processando o arquivo planilha_201901.csv\n",
      "Processando o arquivo planilha_201902.csv\n",
      "Processando o arquivo planilha_201903.csv\n",
      "Processando o arquivo planilha_201904.csv\n",
      "Processando o arquivo planilha_201905.csv\n",
      "Processando o arquivo planilha_201906.csv\n",
      "Processando o arquivo planilha_201907.csv\n",
      "Processando o arquivo planilha_201908.csv\n",
      "Processando o arquivo planilha_201909.csv\n",
      "Processando o arquivo planilha_201910.csv\n",
      "Processando o arquivo planilha_201911.csv\n",
      "Processando o arquivo planilha_201912.csv\n",
      "Processando o arquivo planilha_202001.csv\n",
      "Processando o arquivo planilha_202002.csv\n",
      "Processando o arquivo planilha_202003.csv\n",
      "Processando o arquivo planilha_202004.csv\n",
      "Processando o arquivo planilha_202005.csv\n",
      "Processando o arquivo planilha_202006.csv\n",
      "Processando o arquivo planilha_202007.csv\n",
      "Processando o arquivo planilha_202008.csv\n",
      "Processando o arquivo planilha_202009.csv\n",
      "Processando o arquivo planilha_202010.csv\n",
      "Processando o arquivo planilha_202011.csv\n",
      "Processando o arquivo planilha_202012.csv\n",
      "Processando o arquivo planilha_202101.csv\n",
      "Processando o arquivo planilha_202102.csv\n",
      "Processando o arquivo planilha_202103.csv\n",
      "Processando o arquivo planilha_202104.csv\n",
      "Processando o arquivo planilha_202105.csv\n",
      "Processando o arquivo planilha_202106.csv\n",
      "Processando o arquivo planilha_202107.csv\n",
      "Processando o arquivo planilha_202108.csv\n",
      "Processando o arquivo planilha_202109.csv\n",
      "Processando o arquivo planilha_202110.csv\n",
      "Processando o arquivo planilha_202111.csv\n",
      "Processando o arquivo planilha_202112.csv\n",
      "Processando o arquivo planilha_202201.csv\n",
      "Processando o arquivo planilha_202202.csv\n",
      "Processando o arquivo planilha_202203.csv\n",
      "Processando o arquivo planilha_202204.csv\n",
      "Processando o arquivo planilha_202205.csv\n",
      "Processando o arquivo planilha_202206.csv\n",
      "Processando o arquivo planilha_202207.csv\n",
      "Processando o arquivo planilha_202208.csv\n",
      "Processando o arquivo planilha_202209.csv\n",
      "Processando o arquivo planilha_202210.csv\n",
      "Processando o arquivo planilha_202211.csv\n",
      "Processando o arquivo planilha_202212.csv\n",
      "Processando o arquivo planilha_202301.csv\n",
      "Processando o arquivo planilha_202302.csv\n",
      "Processando o arquivo planilha_202303.csv\n",
      "Processando o arquivo planilha_202304.csv\n",
      "Processando o arquivo planilha_202305.csv\n",
      "Processando o arquivo planilha_202306.csv\n",
      "Processando o arquivo planilha_202307.csv\n",
      "Processando o arquivo planilha_202308.csv\n",
      "Processando o arquivo planilha_202309.csv\n",
      "Processando o arquivo planilha_202310.csv\n",
      "Processando o arquivo planilha_202311.csv\n",
      "Processando o arquivo planilha_202312.csv\n",
      "Processando o arquivo planilha_202401.csv\n",
      "Processando o arquivo planilha_202402.csv\n",
      "Processando o arquivo planilha_202403.csv\n",
      "Processando o arquivo planilha_202404.csv\n",
      "Processando o arquivo planilha_202405.csv\n",
      "Processando o arquivo planilha_202406.csv\n",
      "Processando o arquivo planilha_202407.csv\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('data/raw')\n",
    "files.sort()\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"Operacoes Creditarias\") \\\n",
    "    .set(\"spark.driver.memory\", \"12g\") \\\n",
    "    .set(\"spark.executor.memory\", \"12g\") \\\n",
    "    .set(\"spark.executor.memoryOverhead\", \"12g\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "print(f'Dataset \"Operacoes Creditarias\" em PySpark {spark.version}')\n",
    "\n",
    "df = None\n",
    "for file in files:\n",
    "\tprint(f'Processando o arquivo {file}')\n",
    "\n",
    "\ttemp_df = spark.read.csv(f'data/raw/{file}', sep=';', header=True, encoding='utf-8')\n",
    "\n",
    "\tif TOTAL_ROW_COUNT:\n",
    "\t\trows_per_file = TOTAL_ROW_COUNT // len(files)\n",
    "\t\tfraction = rows_per_file / temp_df.count()\n",
    "\t\ttemp_df = temp_df.sample(withReplacement=False, fraction=fraction, seed=random.randint(0, 10000))\n",
    "\n",
    "\tif df is None:\n",
    "\t\tdf = temp_df\n",
    "\telse:\n",
    "\t\tdf = df.union(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93483354"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de tipagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data_base', 'string'),\n",
       " ('uf', 'string'),\n",
       " ('tcb', 'string'),\n",
       " ('sr', 'string'),\n",
       " ('cliente', 'string'),\n",
       " ('ocupacao', 'string'),\n",
       " ('cnae_secao', 'string'),\n",
       " ('cnae_subclasse', 'string'),\n",
       " ('porte', 'string'),\n",
       " ('modalidade', 'string'),\n",
       " ('origem', 'string'),\n",
       " ('indexador', 'string'),\n",
       " ('numero_de_operacoes', 'string'),\n",
       " ('a_vencer_ate_90_dias', 'string'),\n",
       " ('a_vencer_de_91_ate_360_dias', 'string'),\n",
       " ('a_vencer_de_361_ate_1080_dias', 'string'),\n",
       " ('a_vencer_de_1081_ate_1800_dias', 'string'),\n",
       " ('a_vencer_de_1801_ate_5400_dias', 'string'),\n",
       " ('a_vencer_acima_de_5400_dias', 'string'),\n",
       " ('vencido_acima_de_15_dias', 'string'),\n",
       " ('carteira_ativa', 'string'),\n",
       " ('carteira_inadimplida_arrastada', 'string'),\n",
       " ('ativo_problematico', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_COLS = [\n",
    "    'a_vencer_ate_90_dias',\n",
    "    'a_vencer_de_91_ate_360_dias',\n",
    "    'a_vencer_de_361_ate_1080_dias',\n",
    "    'a_vencer_de_1081_ate_1800_dias',\n",
    "    'a_vencer_de_1801_ate_5400_dias',\n",
    "    'a_vencer_acima_de_5400_dias',\n",
    "    'vencido_acima_de_15_dias',\n",
    "    'carteira_ativa',\n",
    "    'carteira_inadimplida_arrastada',\n",
    "    'ativo_problematico'\n",
    "]\n",
    "CATEGORY_COLS = [\n",
    "    'uf',\n",
    "    'tcb',\n",
    "    'sr',\n",
    "    'ocupacao',\n",
    "    'cnae_secao',\n",
    "    'cnae_subclasse',\n",
    "    'porte',\n",
    "    'modalidade',\n",
    "    'origem',\n",
    "    'indexador'\n",
    "]\n",
    "INT_COLS = [\n",
    "    'numero_de_operacoes'\n",
    "]\n",
    "DATE_COLS = [\n",
    "\t'data_base'\n",
    "]\n",
    "\n",
    "for column in df.columns:\n",
    "\tif column in FLOAT_COLS:\n",
    "\t\tdf = df.withColumn(column, regexp_replace(df[column], ',', '.'))\n",
    "\t\tdf = df.withColumn(column, df[column].cast(DoubleType()))\n",
    "\t\tdf = df.withColumnRenamed(column, 'vl_' + column)\n",
    "\telif column in CATEGORY_COLS:\n",
    "\t\tdf = df.withColumnRenamed(column, 'ct_' + column)\n",
    "\telif column in INT_COLS:\n",
    "\t\tdf = df.withColumn(column, regexp_replace(df[column], '<= ', ''))\n",
    "\t\tdf = df.withColumn(column, df[column].cast(IntegerType()))\n",
    "\t\tdf = df.withColumnRenamed(column, 'nu_' + column)\n",
    "\telif column in DATE_COLS:\n",
    "\t\tdf = df.withColumn(column, to_date(df[column], 'yyyy-MM-dd'))\n",
    "\t\tdf = df.withColumnRenamed(column, 'dt_' + column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dt_data_base', 'date'),\n",
       " ('ct_uf', 'string'),\n",
       " ('ct_tcb', 'string'),\n",
       " ('ct_sr', 'string'),\n",
       " ('cliente', 'string'),\n",
       " ('ct_ocupacao', 'string'),\n",
       " ('ct_cnae_secao', 'string'),\n",
       " ('ct_cnae_subclasse', 'string'),\n",
       " ('ct_porte', 'string'),\n",
       " ('ct_modalidade', 'string'),\n",
       " ('ct_origem', 'string'),\n",
       " ('ct_indexador', 'string'),\n",
       " ('nu_numero_de_operacoes', 'int'),\n",
       " ('vl_a_vencer_ate_90_dias', 'double'),\n",
       " ('vl_a_vencer_de_91_ate_360_dias', 'double'),\n",
       " ('vl_a_vencer_de_361_ate_1080_dias', 'double'),\n",
       " ('vl_a_vencer_de_1081_ate_1800_dias', 'double'),\n",
       " ('vl_a_vencer_de_1801_ate_5400_dias', 'double'),\n",
       " ('vl_a_vencer_acima_de_5400_dias', 'double'),\n",
       " ('vl_vencido_acima_de_15_dias', 'double'),\n",
       " ('vl_carteira_ativa', 'double'),\n",
       " ('vl_carteira_inadimplida_arrastada', 'double'),\n",
       " ('vl_ativo_problematico', 'double')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "    df.groupBy('cliente').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('cliente', 'ct_classificacao')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assim percebemos que já existe uma coluna com a classificação do cliente, então vamos retirar essa informação das outras colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "\tdf.groupBy('ct_porte').count().orderBy('count', ascending=False).show()\n",
    "\tdf.groupBy('ct_modalidade').count().orderBy('count', ascending=False).show()\n",
    "\tdf.groupBy('ct_ocupacao').count().orderBy('count', ascending=False).show()\n",
    "\tdf.groupBy('ct_cnae_secao').count().orderBy('count', ascending=False).show()\n",
    "\tdf.groupBy('ct_cnae_subclasse').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dt_data_base: date, ct_uf: string, ct_tcb: string, ct_sr: string, ct_classificacao: string, ct_ocupacao: string, ct_cnae_secao: string, ct_cnae_subclasse: string, ct_porte: string, ct_modalidade: string, ct_origem: string, ct_indexador: string, nu_numero_de_operacoes: int, vl_a_vencer_ate_90_dias: double, vl_a_vencer_de_91_ate_360_dias: double, vl_a_vencer_de_361_ate_1080_dias: double, vl_a_vencer_de_1081_ate_1800_dias: double, vl_a_vencer_de_1801_ate_5400_dias: double, vl_a_vencer_acima_de_5400_dias: double, vl_vencido_acima_de_15_dias: double, vl_carteira_ativa: double, vl_carteira_inadimplida_arrastada: double, vl_ativo_problematico: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn('ct_porte', trim(substring(col('ct_porte'), 6, 100)))\n",
    "df.withColumn('ct_modalidade', trim(substring(col('ct_modalidade'), 6, 100)))\n",
    "df.withColumn('ct_ocupacao', trim(substring(col('ct_ocupacao'), 6, 100)))\n",
    "df.withColumn('ct_cnae_secao', trim(substring(col('ct_cnae_secao'), 6, 100)))\n",
    "df.withColumn('ct_cnae_subclasse', trim(substring(col('ct_cnae_subclasse'), 6, 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando para zona Trusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/03 20:02:52 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "export_to_file(df, 'data/trusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('vl_carteira_ativa_n_arrastada', col('vl_carteira_ativa') - col('vl_carteira_inadimplida_arrastada'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "\tdf.select('vl_carteira_ativa_n_arrastada').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "\tdf.agg(\n",
    "\t\tsum(when(col('vl_a_vencer_acima_de_5400_dias') != 0.00, 1).otherwise(0)).alias('count_acima_5400'),\n",
    "\t\tsum(when(col('vl_a_vencer_de_1801_ate_5400_dias') != 0.00, 1).otherwise(0)).alias('count_1801_5400'),\n",
    "\t\tsum(when(col('vl_a_vencer_de_361_ate_1080_dias') != 0.00, 1).otherwise(0)).alias('count_361_1080'),\n",
    "\t\tsum(when(col('vl_a_vencer_de_91_ate_360_dias') != 0.00, 1).otherwise(0)).alias('count_91_360'),\n",
    "\t\tsum(when(col('vl_a_vencer_de_1081_ate_1800_dias') != 0.00, 1).otherwise(0)).alias('count_1081_1800'),\n",
    "\t\tsum(when(col('vl_a_vencer_ate_90_dias') != 0.00, 1).otherwise(0)).alias('count_ate_90')\n",
    "\t).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'ct_faixa_meses_ate_vencimento',\n",
    "    when(col('vl_a_vencer_acima_de_5400_dias') != 0.00, '> 180')\n",
    "     .when(col('vl_a_vencer_de_1801_ate_5400_dias') != 0.00, '36-180')\n",
    "     .when(col('vl_a_vencer_de_1081_ate_1800_dias') != 0.00, '18-36')\n",
    "     .when(col('vl_a_vencer_de_361_ate_1080_dias') != 0.00, '12-18')\n",
    "     .when(col('vl_a_vencer_de_91_ate_360_dias') != 0.00, '3-12')\n",
    "     .when(col('vl_a_vencer_ate_90_dias') != 0.00, '0-3')\n",
    "     .otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "\tdf.groupBy('ct_faixa_meses_ate_vencimento').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('vl_media_carteira_ativa_por_operacao', col('vl_carteira_ativa') / col('nu_numero_de_operacoes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "\tdf.groupBy('vl_media_carteira_ativa_por_operacao').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('vl_media_carteira_inadimplida_por_operacao', col('vl_carteira_inadimplida_arrastada') / col('nu_numero_de_operacoes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RESOURCE_VISUALIZATION:\n",
    "\tdf.groupBy('vl_media_carteira_inadimplida_por_operacao').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dt_data_base', 'date'),\n",
       " ('ct_uf', 'string'),\n",
       " ('ct_tcb', 'string'),\n",
       " ('ct_sr', 'string'),\n",
       " ('ct_classificacao', 'string'),\n",
       " ('ct_ocupacao', 'string'),\n",
       " ('ct_cnae_secao', 'string'),\n",
       " ('ct_cnae_subclasse', 'string'),\n",
       " ('ct_porte', 'string'),\n",
       " ('ct_modalidade', 'string'),\n",
       " ('ct_origem', 'string'),\n",
       " ('ct_indexador', 'string'),\n",
       " ('nu_numero_de_operacoes', 'int'),\n",
       " ('vl_a_vencer_ate_90_dias', 'double'),\n",
       " ('vl_a_vencer_de_91_ate_360_dias', 'double'),\n",
       " ('vl_a_vencer_de_361_ate_1080_dias', 'double'),\n",
       " ('vl_a_vencer_de_1081_ate_1800_dias', 'double'),\n",
       " ('vl_a_vencer_de_1801_ate_5400_dias', 'double'),\n",
       " ('vl_a_vencer_acima_de_5400_dias', 'double'),\n",
       " ('vl_vencido_acima_de_15_dias', 'double'),\n",
       " ('vl_carteira_ativa', 'double'),\n",
       " ('vl_carteira_inadimplida_arrastada', 'double'),\n",
       " ('vl_ativo_problematico', 'double'),\n",
       " ('vl_carteira_ativa_n_arrastada', 'double'),\n",
       " ('ct_faixa_meses_ate_vencimento', 'string'),\n",
       " ('vl_media_carteira_ativa_por_operacao', 'double'),\n",
       " ('vl_media_carteira_inadimplida_por_operacao', 'double')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando para zona Refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/03 20:26:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/10/03 20:26:27 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "export_to_file(df, 'data/refined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
